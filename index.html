<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Tiny Chat</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            -webkit-tap-highlight-color: transparent;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif;
            background: #000000;
            color: #ffffff;
            height: 100vh;
            overflow: hidden;
            -webkit-overflow-scrolling: touch;
            position: relative;
            line-height: 1.5;
        }
        
        /* Main App Content */
        .container {
            height: 100vh;
            display: flex;
            flex-direction: column;
            position: relative;
            overflow: hidden;
        }
        
        /* Header */
        .header {
            padding: 16px;
            text-align: center;
            font-size: 18px;
            font-weight: 500;
            color: #ffffff;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
        }
        
        /* Chat Area */
        .chat-area {
            flex: 1;
            overflow-y: auto;
            padding: 16px;
            display: flex;
            flex-direction: column;
            gap: 16px;
        }
        
        /* Messages */
        .message {
            max-width: 85%;
            padding: 14px 18px;
            border-radius: 18px;
            position: relative;
            line-height: 1.6;
            font-size: 16px;
            word-wrap: break-word;
        }
        
        .user-message {
            align-self: flex-end;
            background: #333333;
            color: #ffffff;
            border-bottom-right-radius: 6px;
        }
        
        .ai-message {
            align-self: flex-start;
            background: #222222;
            color: #ffffff;
            border-bottom-left-radius: 6px;
        }
        
        .system-message {
            align-self: center;
            background: #222222;
            color: #999999;
            max-width: 90%;
            font-style: italic;
            border-radius: 18px;
            font-size: 14px;
            padding: 10px 16px;
        }
        
        .loading-dots {
            display: inline-block;
            color: #999999;
        }
        
        .loading-dots::after {
            content: '.';
            animation: dots 1.5s infinite;
            width: 20px;
            display: inline-block;
            text-align: left;
        }
        
        @keyframes dots {
            0%, 20% { content: '.'; }
            40% { content: '..'; }
            60%, 100% { content: '...'; }
        }
        
        /* Input Area */
        .input-area {
            padding: 16px;
            border-top: 1px solid rgba(255, 255, 255, 0.1);
            background: #000000;
            position: relative;
        }
        
        .input-container {
            display: flex;
            gap: 12px;
            max-width: 100%;
        }
        
        .input-field {
            flex: 1;
            background: #111111;
            border: none;
            border-radius: 24px;
            padding: 12px 16px;
            color: #ffffff;
            font-family: inherit;
            font-size: 16px;
            line-height: 1.5;
            min-height: 44px;
            max-height: 200px;
            resize: none;
            outline: none;
            -webkit-appearance: none;
        }
        
        .input-field::placeholder {
            color: #666666;
        }
        
        .send-btn {
            background: #4361ee;
            color: white;
            border: none;
            border-radius: 24px;
            width: 48px;
            height: 48px;
            display: flex;
            align-items: center;
            justify-content: center;
            cursor: pointer;
            flex-shrink: 0;
            transition: all 0.2s ease;
        }
        
        .send-btn:hover {
            background: #3a56d4;
            transform: scale(1.05);
        }
        
        .send-btn:active {
            transform: scale(0.95);
        }
        
        .send-btn:disabled {
            background: #333333;
            cursor: not-allowed;
            transform: none;
        }
        
        .send-btn i {
            font-size: 18px;
        }
        
        /* Hide default scrollbar */
        .chat-area::-webkit-scrollbar {
            display: none;
        }
        
        .chat-area {
            -ms-overflow-style: none;
            scrollbar-width: none;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">New chat</div>
        
        <div class="chat-area" id="chat-box">
            <div class="system-message">
                <strong>System:</strong> Initializing AI agent. This may take a moment as the model downloads (~250MB)...
            </div>
        </div>
        
        <div class="input-area">
            <div class="input-container">
                <textarea id="user-input" class="input-field" placeholder="Ask me anything..." disabled></textarea>
                <button id="send-btn" class="send-btn" disabled>
                    <i class="fas fa-arrow-up"></i>
                </button>
            </div>
        </div>
    </div>

    <script type="module">
        // Using Wllama from CDN
        import { Wllama } from 'https://cdn.jsdelivr.net/npm/@wllama/wllama@2.1.1/esm/index.js';

        const chatBox = document.getElementById('chat-box');
        const userInput = document.getElementById('user-input');
        const sendBtn = document.getElementById('send-btn');
        
        // Conversation history with enhanced context tracking
        let conversationHistory = [];
        
        // SMART AGENT SYSTEM PROMPT - Transforms Pythia into a reasoning agent
        const SYSTEM_PROMPT = `You are TinyAgent, a thoughtful AI assistant. Always:
1. Think step by step before answering
2. Break down complex questions into logical steps
3. Admit when you don't know something
4. Provide concise but complete answers
5. Verify facts internally before responding
6. Avoid speculation - stick to established knowledge
7. If uncertain, say "I'm not certain, but based on general knowledge..."

Reasoning format:
Question: [user question]
Reasoning: First, I need to consider... Next,... Finally,...
Answer: [concise answer]`;

        // Configuration for WASM binaries
        const CONFIG_PATHS = {
            'single-thread/wllama.wasm': 'https://cdn.jsdelivr.net/npm/@wllama/wllama@2.1.1/esm/single-thread/wllama.wasm',
            'multi-thread/wllama.wasm' : 'https://cdn.jsdelivr.net/npm/@wllama/wllama@2.1.1/esm/multi-thread/wllama.wasm',
        };

        const wllama = new Wllama(CONFIG_PATHS);

        // Add message to chat UI
        function addMessage(content, role, isLoading = false) {
            const messageEl = document.createElement('div');
            messageEl.classList.add('message');
            
            if (role === 'user') {
                messageEl.classList.add('user-message');
            } else if (role === 'ai') {
                messageEl.classList.add('ai-message');
                if (isLoading) {
                    messageEl.innerHTML = `<div class="loading-dots">${content}</div>`;
                } else {
                    // Format AI responses with paragraphs
                    const paragraphs = content.split('\n').filter(p => p.trim());
                    messageEl.innerHTML = paragraphs.map(p => `<p>${escapeHtml(p.trim())}</p>`).join('');
                }
            } else if (role === 'system') {
                messageEl.classList.add('system-message');
                messageEl.innerHTML = content;
            } else if (role === 'error') {
                messageEl.classList.add('system-message');
                messageEl.innerHTML = `<strong>Error:</strong> ${escapeHtml(content)}`;
            }
            
            chatBox.appendChild(messageEl);
            chatBox.scrollTop = chatBox.scrollHeight;
            
            if (role === 'user' || role === 'ai') {
                conversationHistory.push({ role, content });
                // Keep history manageable (last 3 exchanges for better context)
                if (conversationHistory.length > 6) {
                    conversationHistory.shift();
                }
            }
            
            return messageEl;
        }
        
        // Escape HTML to prevent XSS
        function escapeHtml(unsafe) {
            return unsafe
                .replace(/&/g, "&amp;")
                .replace(/</g, "&lt;")
                .replace(/>/g, "&gt;")
                .replace(/"/g, "&quot;")
                .replace(/'/g, "&#039;");
        }
        
        // Advanced response cleaning with intelligence-aware processing (Pythia-specific)
        function cleanModelResponse(text) {
            if (!text || typeof text !== 'string') return "I need to think about that more carefully.";
            
            // Pythia doesn't use <|endoftext|> tokens like GPT-2, but may have </s> tokens
            let cleaned = text
                .replace(/<\|pad\|>/g, '')
                .replace(/<\|endoftext\|>/g, '')
                .replace(/<\|unk\|>/g, '')
                .replace(/<\/s>/g, '')  // Pythia stop token
                .trim();
            
            // Extract only the Answer portion if reasoning format was used
            const answerMatch = cleaned.match(/(?:Answer:|answer:|ANSWER:)\s*(.*)/i);
            if (answerMatch && answerMatch[1].trim().length > 5) {
                cleaned = answerMatch[1].trim();
            }
            
            // Remove reasoning traces that leaked into output
            cleaned = cleaned
                .replace(/Reasoning:.*?(?=Answer:|$)/gs, '')
                .replace(/First,.*?Next,.*?Finally,/gs, '')
                .replace(/Let me think step by step\./gi, '')
                .trim();
            
            // Truncate at problematic patterns
            const badPatterns = [
                /\n\s*\n\s*(?:Question|Human|User):/i,
                /<\|/,
                /\n{3,}/,
                /(?:\. ){4,}/,
                /I need to think about that more carefully/i
            ];
            
            for (const pattern of badPatterns) {
                const match = cleaned.match(pattern);
                if (match && match.index > 30) {
                    cleaned = cleaned.substring(0, match.index).trim();
                    break;
                }
            }
            
            // Remove repetitions aggressively
            cleaned = cleaned.replace(/\b(\w+\s*)\1{2,}\b/gi, '$1');
            cleaned = cleaned.replace(/(.{12,}?)\1{1,}/g, '$1');
            
            // Ensure proper sentence ending with intelligence-aware rules
            if (cleaned.length > 15) {
                // Remove trailing incomplete phrases
                cleaned = cleaned.replace(/(?:and so on|etc\.?|and more|I think|maybe|perhaps).*$/gi, '').trim();
                
                // If ends with comma or weak connector, truncate to last strong punctuation
                if (/[,\-â€“â€”]$/g.test(cleaned) || /\b(but|and|or|because)$/i.test(cleaned)) {
                    const lastStrongBreak = cleaned.replace(/[")'\]]+$/, '').lastIndexOf('.');
                    if (lastStrongBreak > cleaned.length - 40 && lastStrongBreak > 25) {
                        cleaned = cleaned.substring(0, lastStrongBreak + 1).trim();
                    }
                }
                
                // Ensure doesn't end with weak phrases
                const weakEndings = [
                    /\s+(and|but|because|although|however|though)$/i,
                    /\s+I think\.?$/i,
                    /\s+maybe\.?$/i,
                    /\s+perhaps\.?$/i,
                    /\s+probably\.?$/i
                ];
                
                for (const pattern of weakEndings) {
                    if (pattern.test(cleaned)) {
                        const lastPeriod = cleaned.lastIndexOf('.');
                        if (lastPeriod > cleaned.length - 50 && lastPeriod > 20) {
                            cleaned = cleaned.substring(0, lastPeriod + 1).trim();
                        }
                        break;
                    }
                }
            }
            
            // Final cleanup
            cleaned = cleaned
                .replace(/\s+/g, ' ')
                .replace(/\n{2,}/g, '\n\n')
                .trim()
                .replace(/^[\s.,;:!?]+|[\s.,;:!?]+$/g, '');
            
            // Quality checks
            if (cleaned.includes('<|') || 
                cleaned.length < 8 || 
                cleaned.split(' ').length < 3 ||
                /^OK\.?$|^Yes\.?$|^No\.?$/i.test(cleaned)) {
                return "I need to think about that more carefully. Could you rephrase or ask something more specific?";
            }
            
            // Add thoughtful closure if response seems cut off
            if (cleaned.length > 40 && !/[.!?]$/.test(cleaned.replace(/[")'\]]+$/, ''))) {
                cleaned += '.';
            }
            
            return cleaned || "I need to think about that more carefully. Could you rephrase your question?";
        }
        
        // Build intelligent prompt with chain-of-thought scaffolding
        function buildPrompt(userMessage) {
            // Start with strong system identity
            let prompt = `${SYSTEM_PROMPT}\n\n`;
            
            // Add recent conversation with reasoning context
            const historyCount = Math.min(3, conversationHistory.length);
            for (let i = conversationHistory.length - historyCount; i < conversationHistory.length; i++) {
                const msg = conversationHistory[i];
                if (msg.role === 'user') {
                    prompt += `Question: ${msg.content}\n`;
                } else if (msg.role === 'ai') {
                    const cleanResp = cleanModelResponse(msg.content);
                    prompt += `Answer: ${cleanResp}\n\n`;
                }
            }
            
            // CRITICAL: Add chain-of-thought scaffolding for current question
            prompt += `Question: ${userMessage}\nReasoning: First, I need to understand the question. `;
            
            // Add domain-specific reasoning hints based on question type
            const lowerMsg = userMessage.toLowerCase();
            if (/\bwhy\b|\bhow\b/.test(lowerMsg)) {
                prompt += `I should break this down into cause-and-effect steps. Next, I'll consider the key factors involved. Finally, I'll formulate a clear explanation.`;
            } else if (/\bwhat is\b|\bdefine\b|\bexplain\b/.test(lowerMsg)) {
                prompt += `I should identify the core concept, its key characteristics, and provide a concise definition with context.`;
            } else if (/\bwhen\b|\bwhere\b/.test(lowerMsg)) {
                prompt += `I need to recall factual information about time or location, being careful not to speculate if uncertain.`;
            } else if (/\bwho\b/.test(lowerMsg)) {
                prompt += `I should identify the person or entity, their significance, and relevant context.`;
            } else {
                prompt += `I'll analyze the key elements of the question, consider relevant knowledge, and provide a thoughtful response.`;
            }
            
            prompt += `\nAnswer:`;
            return prompt;
        }

        async function init() {
            try {
                addMessage("Initializing AI agent with enhanced reasoning capabilities...", "system");
                
                // Load model - CORRECTED REPOSITORY (TheBloke maintains GGUF quantizations)
                await wllama.loadModelFromHF(
                    'TheBloke/pythia-410m-deduped-GGUF',  // CORRECT REPOSITORY
                    'pythia-410m-deduped.Q4_K_M.gguf',     // CORRECT FILENAME
                    {
                        progressCallback: ({ loaded, total }) => {
                            const progress = Math.round((loaded / total) * 100);
                            if (progress % 10 === 0 || progress === 100) {
                                const existing = chatBox.querySelector('.download-progress');
                                if (existing) {
                                    existing.textContent = `Downloading AI agent: ${progress}%`;
                                } else if (progress < 100) {
                                    const el = document.createElement('div');
                                    el.classList.add('system-message', 'download-progress');
                                    el.textContent = `Downloading AI agent: ${progress}%`;
                                    chatBox.appendChild(el);
                                    chatBox.scrollTop = chatBox.scrollHeight;
                                }
                            }
                        }
                    }
                );

                addMessage("I'm ready. I've been enhanced with step-by-step reasoning capabilities. Ask me anythingâ€”I'll think carefully before responding.", "ai");
                addMessage("ðŸ’¡ I work best with clear, specific questions. I'll admit when I'm uncertain.", "system");
                
                userInput.disabled = false;
                sendBtn.disabled = false;
                userInput.focus();
            } catch (err) {
                const errorMsg = err.message || 'Failed to load AI agent. Try refreshing or using Chrome/Firefox.';
                addMessage(errorMsg, "error");
                console.error("Model loading error:", err);
                console.error("Troubleshooting tips:");
                console.error("1. Correct repository: TheBloke/pythia-410m-deduped-GGUF");
                console.error("2. Correct filename: pythia-410m-deduped.Q4_K_M.gguf");
                console.error("3. File size: ~250MB (larger than GPT-2 due to Pythia architecture)");
                console.error("4. Ensure you're using Chrome/Firefox with WASM support");
            }
        }
        
        async function handleChat() {
            const text = userInput.value.trim();
            if (!text) return;

            // Add user message
            addMessage(text, 'user');
            userInput.value = '';
            userInput.style.height = 'auto';
            
            // Show loading indicator with intelligent status
            const loadingEl = addMessage("Thinking carefully...", 'ai', true);
            sendBtn.disabled = true;
            userInput.disabled = true;
            
            try {
                const prompt = buildPrompt(text);
                
                // Generate response with agent-optimized parameters
                const response = await wllama.createCompletion(prompt, {
                    nPredict: 150, // Allow room for reasoning
                    sampling: { 
                        temp: 0.55,          // Lower temp for factual reliability
                        top_k: 35,           // Focused token selection
                        top_p: 0.85,         // Tighter nucleus sampling
                        repeat_penalty: 1.45, // Strong repetition prevention
                        frequency_penalty: 0.5 // Aggressive repetition control
                    }
                });
                
                // Clean and enhance the response
                let cleanedResponse = cleanModelResponse(response);
                
                // Add thoughtful qualifiers for uncertain domains
                const lowerResp = cleanedResponse.toLowerCase();
                const lowerQ = text.toLowerCase();
                
                // If question is about current events/post-2019, add disclaimer
                if ((/\b202[3456789]\b|\btoday\b|\bcurrent\b|\blatest\b|\brecent\b/.test(lowerQ) || 
                     /\bjust happened\b|\bnews\b|\btrending\b/.test(lowerQ)) && 
                    !/history|past|historical/.test(lowerQ)) {
                    if (!cleanedResponse.includes("training data") && !cleanedResponse.includes("cutoff")) {
                        cleanedResponse += " Note: My knowledge has a cutoff and I can't access real-time information.";
                    }
                }
                
                // If response seems uncertain, enhance with agent-like humility
                if (/\bmaybe\b|\bperhaps\b|\bprobably\b|\bI think\b/i.test(lowerResp) && 
                    !cleanedResponse.includes("not certain")) {
                    cleanedResponse = cleanedResponse.replace(/\b(I think|maybe|perhaps|probably)\b/gi, 'I\'m not entirely certain, but');
                }
                
                // Replace loading indicator with thoughtful response
                loadingEl.remove();
                addMessage(cleanedResponse, 'ai');
                
            } catch (err) {
                console.error("Error generating response:", err);
                loadingEl.remove();
                addMessage("I encountered a reasoning error. Let me try approaching this differently. Could you rephrase your question?", "ai");
            } finally {
                sendBtn.disabled = false;
                userInput.disabled = false;
                userInput.focus();
            }
        }

        sendBtn.addEventListener('click', handleChat);
        userInput.addEventListener('keypress', (e) => { 
            if (e.key === 'Enter' && !e.shiftKey) {
                e.preventDefault();
                handleChat();
            }
        });
        
        // Auto-resize textarea
        userInput.addEventListener('input', () => {
            userInput.style.height = 'auto';
            userInput.style.height = Math.min(200, userInput.scrollHeight) + 'px';
        });

        // Initialize the app
        init();
    </script>
</body>
</html>

