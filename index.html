<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Tiny Chat</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            -webkit-tap-highlight-color: transparent;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif;
            background: #000000;
            color: #ffffff;
            height: 100vh;
            overflow: hidden;
            -webkit-overflow-scrolling: touch;
            position: relative;
            line-height: 1.5;
        }
        
        /* Main App Content */
        .container {
            height: 100vh;
            display: flex;
            flex-direction: column;
            position: relative;
            overflow: hidden;
        }
        
        /* Header */
        .header {
            padding: 16px;
            text-align: center;
            font-size: 18px;
            font-weight: 500;
            color: #ffffff;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
        }
        
        /* Chat Area */
        .chat-area {
            flex: 1;
            overflow-y: auto;
            padding: 16px;
            display: flex;
            flex-direction: column;
            gap: 16px;
        }
        
        /* Messages */
        .message {
            max-width: 85%;
            padding: 14px 18px;
            border-radius: 18px;
            position: relative;
            line-height: 1.6;
            font-size: 16px;
            word-wrap: break-word;
        }
        
        .user-message {
            align-self: flex-end;
            background: #333333;
            color: #ffffff;
            border-bottom-right-radius: 6px;
        }
        
        .ai-message {
            align-self: flex-start;
            background: #222222;
            color: #ffffff;
            border-bottom-left-radius: 6px;
        }
        
        .system-message {
            align-self: center;
            background: #222222;
            color: #999999;
            max-width: 90%;
            font-style: italic;
            border-radius: 18px;
            font-size: 14px;
            padding: 10px 16px;
        }
        
        .error-message {
            background: #4a0000;
            color: #ff8888;
            border-radius: 18px;
            padding: 12px 16px;
            max-width: 90%;
            font-size: 15px;
            line-height: 1.5;
            border-left: 3px solid #ff4444;
        }
        
        .loading-dots {
            display: inline-block;
            color: #999999;
        }
        
        .loading-dots::after {
            content: '.';
            animation: dots 1.5s infinite;
            width: 20px;
            display: inline-block;
            text-align: left;
        }
        
        @keyframes dots {
            0%, 20% { content: '.'; }
            40% { content: '..'; }
            60%, 100% { content: '...'; }
        }
        
        /* Input Area */
        .input-area {
            padding: 16px;
            border-top: 1px solid rgba(255, 255, 255, 0.1);
            background: #000000;
            position: relative;
        }
        
        .input-container {
            display: flex;
            gap: 12px;
            max-width: 100%;
        }
        
        .input-field {
            flex: 1;
            background: #111111;
            border: none;
            border-radius: 24px;
            padding: 12px 16px;
            color: #ffffff;
            font-family: inherit;
            font-size: 16px;
            line-height: 1.5;
            min-height: 44px;
            max-height: 200px;
            resize: none;
            outline: none;
            -webkit-appearance: none;
        }
        
        .input-field::placeholder {
            color: #666666;
        }
        
        .send-btn {
            background: #4361ee;
            color: white;
            border: none;
            border-radius: 24px;
            width: 48px;
            height: 48px;
            display: flex;
            align-items: center;
            justify-content: center;
            cursor: pointer;
            flex-shrink: 0;
            transition: all 0.2s ease;
        }
        
        .send-btn:hover {
            background: #3a56d4;
            transform: scale(1.05);
        }
        
        .send-btn:active {
            transform: scale(0.95);
        }
        
        .send-btn:disabled {
            background: #333333;
            cursor: not-allowed;
            transform: none;
        }
        
        .send-btn i {
            font-size: 18px;
        }
        
        /* Hide default scrollbar */
        .chat-area::-webkit-scrollbar {
            display: none;
        }
        
        .chat-area {
            -ms-overflow-style: none;
            scrollbar-width: none;
        }
        
        /* Diagnostic code styling */
        .diagnostic-code {
            background: #333333;
            color: #ffcc00;
            font-family: monospace;
            font-size: 13px;
            padding: 4px 8px;
            border-radius: 6px;
            margin-top: 8px;
            display: inline-block;
        }
        
        .diagnostic-steps {
            background: #2a2a2a;
            border-radius: 12px;
            padding: 12px;
            margin-top: 12px;
            font-size: 14px;
            line-height: 1.5;
        }
        
        .diagnostic-steps ul {
            padding-left: 20px;
            margin-top: 8px;
        }
        
        .diagnostic-steps li {
            margin-bottom: 6px;
        }
        
        .diagnostic-steps strong {
            color: #4a90e2;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">New chat</div>
        
        <div class="chat-area" id="chat-box">
            <div class="system-message">
                <strong>System:</strong> Initializing AI agent. This may take a moment as the model downloads (~250MB)...
            </div>
        </div>
        
        <div class="input-area">
            <div class="input-container">
                <textarea id="user-input" class="input-field" placeholder="Ask me anything..." disabled></textarea>
                <button id="send-btn" class="send-btn" disabled>
                    <i class="fas fa-arrow-up"></i>
                </button>
            </div>
        </div>
    </div>

    <script type="module">
        // Using Wllama from CDN
        import { Wllama } from 'https://cdn.jsdelivr.net/npm/@wllama/wllama@2.1.1/esm/index.js';

        const chatBox = document.getElementById('chat-box');
        const userInput = document.getElementById('user-input');
        const sendBtn = document.getElementById('send-btn');
        
        // Conversation history with enhanced context tracking
        let conversationHistory = [];
        
        // SMART AGENT SYSTEM PROMPT - Transforms Pythia into a reasoning agent
        const SYSTEM_PROMPT = `You are TinyAgent, a thoughtful AI assistant. Always:
1. Think step by step before answering
2. Break down complex questions into logical steps
3. Admit when you don't know something
4. Provide concise but complete answers
5. Verify facts internally before responding
6. Avoid speculation - stick to established knowledge
7. If uncertain, say "I'm not certain, but based on general knowledge..."

Reasoning format:
Question: [user question]
Reasoning: First, I need to consider... Next,... Finally,...
Answer: [concise answer]`;

        // Configuration for WASM binaries
        const CONFIG_PATHS = {
            'single-thread/wllama.wasm': 'https://cdn.jsdelivr.net/npm/@wllama/wllama@2.1.1/esm/single-thread/wllama.wasm',
            'multi-thread/wllama.wasm' : 'https://cdn.jsdelivr.net/npm/@wllama/wllama@2.1.1/esm/multi-thread/wllama.wasm',
        };

        const wllama = new Wllama(CONFIG_PATHS);

        // Add message to chat UI
        function addMessage(content, role, isLoading = false) {
            const messageEl = document.createElement('div');
            messageEl.classList.add('message');
            
            if (role === 'user') {
                messageEl.classList.add('user-message');
            } else if (role === 'ai') {
                messageEl.classList.add('ai-message');
                if (isLoading) {
                    messageEl.innerHTML = `<div class="loading-dots">${content}</div>`;
                } else {
                    // Format AI responses with paragraphs
                    const paragraphs = content.split('\n').filter(p => p.trim());
                    messageEl.innerHTML = paragraphs.map(p => `<p>${escapeHtml(p.trim())}</p>`).join('');
                }
            } else if (role === 'system') {
                messageEl.classList.add('system-message');
                messageEl.innerHTML = content;
            } else if (role === 'error') {
                messageEl.classList.add('error-message');
                messageEl.innerHTML = content;
            }
            
            chatBox.appendChild(messageEl);
            chatBox.scrollTop = chatBox.scrollHeight;
            
            if (role === 'user' || role === 'ai') {
                conversationHistory.push({ role, content });
                // Keep history manageable (last 3 exchanges for better context)
                if (conversationHistory.length > 6) {
                    conversationHistory.shift();
                }
            }
            
            return messageEl;
        }
        
        // Escape HTML to prevent XSS
        function escapeHtml(unsafe) {
            return unsafe
                .replace(/&/g, "&amp;")
                .replace(/</g, "&lt;")
                .replace(/>/g, "&gt;")
                .replace(/"/g, "&quot;")
                .replace(/'/g, "&#039;");
        }
        
        // Advanced response cleaning with intelligence-aware processing (Pythia-specific)
        function cleanModelResponse(text) {
            if (!text || typeof text !== 'string') return "I need to think about that more carefully.";
            
            // Pythia doesn't use 1 tokens like GPT-2, but may have </s> tokens
            let cleaned = text
                .replace(/<\|pad\|>/g, '')
                .replace(/<\|endoftext\|>/g, '')
                .replace(/<\|unk\|>/g, '')
                .replace(/<\/s>/g, '')  // Pythia stop token
                .trim();
            
            // Extract only the Answer portion if reasoning format was used
            const answerMatch = cleaned.match(/(?:Answer:|answer:|ANSWER:)\s*(.*)/i);
            if (answerMatch && answerMatch[1].trim().length > 5) {
                cleaned = answerMatch[1].trim();
            }
            
            // Remove reasoning traces that leaked into output
            cleaned = cleaned
                .replace(/Reasoning:.*?(?=Answer:|$)/gs, '')
                .replace(/First,.*?Next,.*?Finally,/gs, '')
                .replace(/Let me think step by step\./gi, '')
                .trim();
            
            // Truncate at problematic patterns
            const badPatterns = [
                /\n\s*\n\s*(?:Question|Human|User):/i,
                /<\|/,
                /\n{3,}/,
                /(?:\. ){4,}/,
                /I need to think about that more carefully/i
            ];
            
            for (const pattern of badPatterns) {
                const match = cleaned.match(pattern);
                if (match && match.index > 30) {
                    cleaned = cleaned.substring(0, match.index).trim();
                    break;
                }
            }
            
            // Remove repetitions aggressively
            cleaned = cleaned.replace(/\b(\w+\s*)\1{2,}\b/gi, '$1');
            cleaned = cleaned.replace(/(.{12,}?)\1{1,}/g, '$1');
            
            // Ensure proper sentence ending with intelligence-aware rules
            if (cleaned.length > 15) {
                // Remove trailing incomplete phrases
                cleaned = cleaned.replace(/(?:and so on|etc\.?|and more|I think|maybe|perhaps).*$/gi, '').trim();
                
                // If ends with comma or weak connector, truncate to last strong punctuation
                if (/[,\-â€“â€”]$/g.test(cleaned) || /\b(but|and|or|because)$/i.test(cleaned)) {
                    const lastStrongBreak = cleaned.replace(/[")'\]]+$/, '').lastIndexOf('.');
                    if (lastStrongBreak > cleaned.length - 40 && lastStrongBreak > 25) {
                        cleaned = cleaned.substring(0, lastStrongBreak + 1).trim();
                    }
                }
                
                // Ensure doesn't end with weak phrases
                const weakEndings = [
                    /\s+(and|but|because|although|however|though)$/i,
                    /\s+I think\.?$/i,
                    /\s+maybe\.?$/i,
                    /\s+perhaps\.?$/i,
                    /\s+probably\.?$/i
                ];
                
                for (const pattern of weakEndings) {
                    if (pattern.test(cleaned)) {
                        const lastPeriod = cleaned.lastIndexOf('.');
                        if (lastPeriod > cleaned.length - 50 && lastPeriod > 20) {
                            cleaned = cleaned.substring(0, lastPeriod + 1).trim();
                        }
                        break;
                    }
                }
            }
            
            // Final cleanup
            cleaned = cleaned
                .replace(/\s+/g, ' ')
                .replace(/\n{2,}/g, '\n\n')
                .trim()
                .replace(/^[\s.,;:!?]+|[\s.,;:!?]+$/g, '');
            
            // Quality checks
            if (cleaned.includes('<|') || 
                cleaned.length < 8 || 
                cleaned.split(' ').length < 3 ||
                /^OK\.?$|^Yes\.?$|^No\.?$/i.test(cleaned)) {
                return "I need to think about that more carefully. Could you rephrase or ask something more specific?";
            }
            
            // Add thoughtful closure if response seems cut off
            if (cleaned.length > 40 && !/[.!?]$/.test(cleaned.replace(/[")'\]]+$/, ''))) {
                cleaned += '.';
            }
            
            return cleaned || "I need to think about that more carefully. Could you rephrase your question?";
        }
        
        // Build intelligent prompt with chain-of-thought scaffolding
        function buildPrompt(userMessage) {
            // Start with strong system identity
            let prompt = `${SYSTEM_PROMPT}\n\n`;
            
            // Add recent conversation with reasoning context
            const historyCount = Math.min(3, conversationHistory.length);
            for (let i = conversationHistory.length - historyCount; i < conversationHistory.length; i++) {
                const msg = conversationHistory[i];
                if (msg.role === 'user') {
                    prompt += `Question: ${msg.content}\n`;
                } else if (msg.role === 'ai') {
                    const cleanResp = cleanModelResponse(msg.content);
                    prompt += `Answer: ${cleanResp}\n\n`;
                }
            }
            
            // CRITICAL: Add chain-of-thought scaffolding for current question
            prompt += `Question: ${userMessage}\nReasoning: First, I need to understand the question. `;
            
            // Add domain-specific reasoning hints based on question type
            const lowerMsg = userMessage.toLowerCase();
            if (/\bwhy\b|\bhow\b/.test(lowerMsg)) {
                prompt += `I should break this down into cause-and-effect steps. Next, I'll consider the key factors involved. Finally, I'll formulate a clear explanation.`;
            } else if (/\bwhat is\b|\bdefine\b|\bexplain\b/.test(lowerMsg)) {
                prompt += `I should identify the core concept, its key characteristics, and provide a concise definition with context.`;
            } else if (/\bwhen\b|\bwhere\b/.test(lowerMsg)) {
                prompt += `I need to recall factual information about time or location, being careful not to speculate if uncertain.`;
            } else if (/\bwho\b/.test(lowerMsg)) {
                prompt += `I should identify the person or entity, their significance, and relevant context.`;
            } else {
                prompt += `I'll analyze the key elements of the question, consider relevant knowledge, and provide a thoughtful response.`;
            }
            
            prompt += `\nAnswer:`;
            return prompt;
        }

        // Diagnostic error analyzer
        function analyzeError(error, url) {
            const diag = {
                code: 'ERR_UNKNOWN_000',
                title: 'Unknown Error',
                description: 'An unexpected error occurred while loading the model.',
                steps: [
                    'Check your internet connection',
                    'Try refreshing the page',
                    'If the problem persists, contact support'
                ]
            };
            
            // Common error patterns
            if (error.message.includes('CORS') || 
                error.message.includes('cors') || 
                error.message.includes('cross-origin')) {
                diag.code = 'ERR_CORS_001';
                diag.title = 'CORS Error';
                diag.description = 'The model server does not allow cross-origin requests from your browser.';
                diag.steps = [
                    'The model URL must have CORS headers enabled',
                    'Contact the model host to add "Access-Control-Allow-Origin: *" header',
                    'Try using Hugging Face Hub or jsDelivr for hosting'
                ];
            }
            
            else if (error.message.includes('404') || 
                     error.message.includes('not found') || 
                     error.message.includes('403')) {
                diag.code = 'ERR_FILE_002';
                diag.title = 'Model File Not Found';
                diag.description = 'The model file could not be found at the specified URL.';
                diag.steps = [
                    'Verify the URL is correct: ' + url,
                    'Check if the file exists at that location',
                    'If using GitHub, ensure you\'re using the raw URL or jsDelivr',
                    'For GitHub: Use "https://cdn.jsdelivr.net/gh/username/repo@main/filename.gguf"'
                ];
            }
            
            else if (error.message.includes('network') || 
                     error.message.includes('offline') || 
                     error.message.includes('fetch')) {
                diag.code = 'ERR_NETWORK_003';
                diag.title = 'Network Error';
                diag.description = 'Could not connect to the model server.';
                diag.steps = [
                    'Check your internet connection',
                    'Try refreshing the page',
                    'If using a proxy or firewall, check your network settings'
                ];
            }
            
            else if (error.message.includes('invalid') || 
                     error.message.includes('format') || 
                     error.message.includes('magic')) {
                diag.code = 'ERR_MODEL_004';
                diag.title = 'Invalid Model Format';
                diag.description = 'The model file is corrupted or not in the expected format.';
                diag.steps = [
                    'Verify the file is a valid GGUF model',
                    'Check if the file was downloaded completely',
                    'Try using a different quantization (e.g., Q4_K_M instead of Q5_K_M)'
                ];
            }
            
            else if (error.message.includes('WebAssembly') || 
                     error.message.includes('wasm') || 
                     error.message.includes('instantiate')) {
                diag.code = 'ERR_BROWSER_005';
                diag.title = 'Browser Compatibility Issue';
                diag.description = 'Your browser may not support WebAssembly features required by the model.';
                diag.steps = [
                    'Try using Chrome or Firefox (Safari may have issues)',
                    'Ensure your browser is up-to-date',
                    'Check for browser extensions that might block WebAssembly'
                ];
            }
            
            return diag;
        }

        async function init() {
            try {
                addMessage("Initializing AI agent with enhanced reasoning capabilities...", "system");
                
                // Load model - CORRECTED REPOSITORY (TheBloke maintains GGUF quantizations)
                await wllama.loadModelFromHF(
                    'TheBloke/pythia-410m-deduped-GGUF',  // CORRECT REPOSITORY
                    'pythia-410m-deduped.Q4_K_M.gguf',     // CORRECT FILENAME
                    {
                        progressCallback: ({ loaded, total }) => {
                            const progress = Math.round((loaded / total) * 100);
                            if (progress % 10 === 0 || progress === 100) {
                                const existing = chatBox.querySelector('.download-progress');
                                if (existing) {
                                    existing.textContent = `Downloading AI agent: ${progress}%`;
                                } else if (progress < 100) {
                                    const el = document.createElement('div');
                                    el.classList.add('system-message', 'download-progress');
                                    el.textContent = `Downloading AI agent: ${progress}%`;
                                    chatBox.appendChild(el);
                                    chatBox.scrollTop = chatBox.scrollHeight;
                                }
                            }
                        }
                    }
                );

                addMessage("I'm ready. I've been enhanced with step-by-step reasoning capabilities. Ask me anythingâ€”I'll think carefully before responding.", "ai");
                addMessage("ðŸ’¡ I work best with clear, specific questions. I'll admit when I'm uncertain.", "system");
                
                userInput.disabled = false;
                sendBtn.disabled = false;
                userInput.focus();
            } catch (err) {
                const modelUrl = 'https://huggingface.co/TheBloke/pythia-410m-deduped-GGUF/resolve/main/pythia-410m-deduped.Q4_K_M.gguf';
                const diag = analyzeError(err, modelUrl);
                
                const errorMsg = `
                    <strong>Model Loading Failed</strong>
                    <div class="diagnostic-code">DIAGNOSTIC: ${diag.code}</div>
                    <p><strong>${diag.title}</strong></p>
                    <p>${diag.description}</p>
                    
                    <div class="diagnostic-steps">
                        <strong>Troubleshooting steps:</strong>
                        <ul>
                            ${diag.steps.map(step => `<li>${step}</li>`).join('')}
                        </ul>
                    </div>
                    
                    <p><strong>Technical details:</strong> ${err.message}</p>
                `;
                
                addMessage(errorMsg, "error");
                console.error("Model loading error:", err);
                console.error("Diagnostic code:", diag.code);
                console.error("Error details:", diag);
            }
        }
        
        async function handleChat() {
            const text = userInput.value.trim();
            if (!text) return;

            // Add user message
            addMessage(text, 'user');
            userInput.value = '';
            userInput.style.height = 'auto';
            
            // Show loading indicator with intelligent status
            const loadingEl = addMessage("Thinking carefully...", 'ai', true);
            sendBtn.disabled = true;
            userInput.disabled = true;
            
            try {
                const prompt = buildPrompt(text);
                
                // Generate response with agent-optimized parameters
                const response = await wllama.createCompletion(prompt, {
                    nPredict: 150, // Allow room for reasoning
                    sampling: { 
                        temp: 0.55,          // Lower temp for factual reliability
                        top_k: 35,           // Focused token selection
                        top_p: 0.85,         // Tighter nucleus sampling
                        repeat_penalty: 1.45, // Strong repetition prevention
                        frequency_penalty: 0.5 // Aggressive repetition control
                    }
                });
                
                // Clean and enhance the response
                let cleanedResponse = cleanModelResponse(response);
                
                // Add thoughtful qualifiers for uncertain domains
                const lowerResp = cleanedResponse.toLowerCase();
                const lowerQ = text.toLowerCase();
                
                // If question is about current events/post-2019, add disclaimer
                if ((/\b202[3456789]\b|\btoday\b|\bcurrent\b|\blatest\b|\brecent\b/.test(lowerQ) || 
                     /\bjust happened\b|\bnews\b|\btrending\b/.test(lowerQ)) && 
                    !/history|past|historical/.test(lowerQ)) {
                    if (!cleanedResponse.includes("training data") && !cleanedResponse.includes("cutoff")) {
                        cleanedResponse += " Note: My knowledge has a cutoff and I can't access real-time information.";
                    }
                }
                
                // If response seems uncertain, enhance with agent-like humility
                if (/\bmaybe\b|\bperhaps\b|\bprobably\b|\bI think\b/i.test(lowerResp) && 
                    !cleanedResponse.includes("not certain")) {
                    cleanedResponse = cleanedResponse.replace(/\b(I think|maybe|perhaps|probably)\b/gi, 'I\'m not entirely certain, but');
                }
                
                // Replace loading indicator with thoughtful response
                loadingEl.remove();
                addMessage(cleanedResponse, 'ai');
                
            } catch (err) {
                console.error("Error generating response:", err);
                loadingEl.remove();
                addMessage("I encountered a reasoning error. Let me try approaching this differently. Could you rephrase your question?", "ai");
            } finally {
                sendBtn.disabled = false;
                userInput.disabled = false;
                userInput.focus();
            }
        }

        sendBtn.addEventListener('click', handleChat);
        userInput.addEventListener('keypress', (e) => { 
            if (e.key === 'Enter' && !e.shiftKey) {
                e.preventDefault();
                handleChat();
            }
        });
        
        // Auto-resize textarea
        userInput.addEventListener('input', () => {
            userInput.style.height = 'auto';
            userInput.style.height = Math.min(200, userInput.scrollHeight) + 'px';
        });

        // Initialize the app
        init();
    </script>
</body>
</html>

